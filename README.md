
# ğŸ¦ Real-Time Twitter Sentiment Analysis

This project performs **real-time sentiment analysis** on live Twitter data using **Apache Kafka**, **Apache Spark**, and **PySpark ML**. It streams tweets, processes them using a trained machine learning model, and displays sentiment predictions (positive, negative, neutral) in real-time.

---

## ğŸš€ Project Features

- âœ… Real-time tweet streaming using Tweepy & Twitter API v2
- âœ… Apache Kafka for distributed message ingestion
- âœ… Apache Spark Streaming for processing and inference
- âœ… ML pipeline using PySpark (Tokenizer, TF-IDF, Logistic Regression)
- âœ… Visual dashboard (optional via Streamlit or Plotly)
- âœ… Deployable on local machine or cloud

---

## ğŸ§± Tech Stack

| Component       | Technology           |
|----------------|----------------------|
| Language        | Python 3.x           |
| Data Streaming  | Apache Kafka         |
| Processing      | Apache Spark + PySpark |
| ML Model        | Spark ML Pipeline    |
| Data Source     | Twitter API (Tweepy) |
| Packaging       | Docker (optional)    |

---

## ğŸ“‚ Project Structure

```
Real-Time-Twitter-Sentiment-Analysis/
â”œâ”€â”€ Kafka-PySpark/                 # Spark Streaming consumer
â”‚   â””â”€â”€ tweet_consumer.py
â”œâ”€â”€ ML PySpark Model/             # Model training & CSV data
â”‚   â”œâ”€â”€ train_model.py
â”‚   â”œâ”€â”€ run_model_local.py
â”‚   â”œâ”€â”€ twitter_training.csv
â”‚   â””â”€â”€ sentiment_model/         # Saved PySpark PipelineModel
â”œâ”€â”€ Django-Dashboard/             # Optional UI (future)
â”œâ”€â”€ zk-single-kafka-single.yml    # Docker Compose for Kafka & Zookeeper
â””â”€â”€ requirements.txt
```

---

## ğŸ§ª How to Run the Project

### 1. âœ… Install Dependencies

```bash
pip install -r requirements.txt
```

Make sure Java 11+ and Spark are installed and configured.

### 2. âœ… Train the Model (or use pretrained)

```bash
cd "ML PySpark Model"
python train_model.py
```

This will generate a `sentiment_model/` folder.

### 3. âœ… Start Kafka and Zookeeper

```bash
docker compose -f zk-single-kafka-single.yml up
```

### 4. âœ… Run Twitter Stream Producer

```bash
python twitter_producer.py
```

This sends live tweets to a Kafka topic.

### 5. âœ… Run Spark Consumer

```bash
python Kafka-PySpark/tweet_consumer.py
```

This consumes the tweets, predicts sentiment, and prints the output.

---

## ğŸ“Š Sample Output

```
Tweet: "I love the new iPhone!"
Sentiment: Positive (0.0)

Tweet: "This is the worst update ever..."
Sentiment: Negative (1.0)
```

---

## âš™ï¸ Model Details

- Preprocessing: Tokenizer, StopWordsRemover, HashingTF, IDF
- Classifier: Logistic Regression
- Training Data: Cleaned from `twitter_training.csv`

---

## ğŸ“ To-Do / Improvements

- [ ] Improve classification with deep learning models (BERT, RoBERTa)
- [ ] Add visualization dashboard (Streamlit)
- [ ] Enable multi-language tweet support
- [ ] Deploy on cloud (AWS/GCP/Azure)

---

## ğŸ™Œ Contributors

- **Mitali Trivedi**
- **Kazi Afroz Alam**
- **Mateen Khan**
- **Ranjit Kumar Behera**

---

## ğŸ“œ License

This project is licensed under the [MIT License](LICENSE).
